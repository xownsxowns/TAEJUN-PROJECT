{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "- raw data, no feature extraction\n",
    "- parietal, occipital region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/[3] 수업/ME특론1/dataset/ME1.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.loadmat(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 1150, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  5\n",
       "1  0\n",
       "2  4\n",
       "3  1\n",
       "4  9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = pd.read_csv('E:/[3] 수업/ME특론1/dataset/label.txt',header=None, engine='python')\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "- input shape: samples x time steps x features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = np.reshape(data['data'][:,150:,:],(500,1000,29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=10 , input_shape=(1000, 29)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-3c7ddc9983ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "label = label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "446/446 [==============================] - 6s 13ms/step - loss: 2.5833 - acc: 0.0695\n",
      "Epoch 2/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 1.9938 - acc: 0.3117\n",
      "Epoch 3/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 1.4784 - acc: 0.5673\n",
      "Epoch 4/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.9952 - acc: 0.8072\n",
      "Epoch 5/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.6238 - acc: 0.9417\n",
      "Epoch 6/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.4095 - acc: 0.9821\n",
      "Epoch 7/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.2766 - acc: 0.9978\n",
      "Epoch 8/20\n",
      "446/446 [==============================] - 5s 11ms/step - loss: 0.2083 - acc: 0.9955\n",
      "Epoch 9/20\n",
      "446/446 [==============================] - 5s 12ms/step - loss: 0.1511 - acc: 0.9978\n",
      "Epoch 10/20\n",
      "446/446 [==============================] - 5s 12ms/step - loss: 0.1331 - acc: 0.9978\n",
      "Epoch 11/20\n",
      "446/446 [==============================] - 5s 11ms/step - loss: 0.0997 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0621 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0704 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0627 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0388 - acc: 1.0000\n",
      "acc: 11.11%\n",
      "Epoch 1/20\n",
      "446/446 [==============================] - 6s 14ms/step - loss: 2.5789 - acc: 0.1121\n",
      "Epoch 2/20\n",
      "446/446 [==============================] - 5s 11ms/step - loss: 1.9297 - acc: 0.3834\n",
      "Epoch 3/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 1.3770 - acc: 0.6592\n",
      "Epoch 4/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.8474 - acc: 0.8744\n",
      "Epoch 5/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.5366 - acc: 0.9664\n",
      "Epoch 6/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.3675 - acc: 0.9933\n",
      "Epoch 7/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.2628 - acc: 0.9978\n",
      "Epoch 8/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.1893 - acc: 0.9978\n",
      "Epoch 9/20\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.1571 - acc: 0.9978\n",
      "Epoch 10/20\n",
      "446/446 [==============================] - 5s 11ms/step - loss: 0.1295 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "446/446 [==============================] - 5s 11ms/step - loss: 0.1005 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0759 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0549 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "446/446 [==============================] - 5s 11ms/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "446/446 [==============================] - 5s 10ms/step - loss: 0.0334 - acc: 1.0000\n",
      "acc: 7.41%\n",
      "Epoch 1/20\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 2.5895 - acc: 0.0869\n",
      "Epoch 2/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 1.9591 - acc: 0.3898\n",
      "Epoch 3/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 1.4130 - acc: 0.6437\n",
      "Epoch 4/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.9265 - acc: 0.8285\n",
      "Epoch 5/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.5778 - acc: 0.9399\n",
      "Epoch 6/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.3796 - acc: 0.9889\n",
      "Epoch 7/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.2439 - acc: 0.9978\n",
      "Epoch 8/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.1961 - acc: 0.9978\n",
      "Epoch 9/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.1389 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.1080 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0928 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0705 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0688 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0279 - acc: 1.0000\n",
      "acc: 13.73%\n",
      "Epoch 1/20\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 2.5765 - acc: 0.0557\n",
      "Epoch 2/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 1.9378 - acc: 0.3742\n",
      "Epoch 3/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 1.4144 - acc: 0.6192\n",
      "Epoch 4/20\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 0.8324 - acc: 0.8597\n",
      "Epoch 5/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.4978 - acc: 0.9577\n",
      "Epoch 6/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.3102 - acc: 0.9978\n",
      "Epoch 7/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.2315 - acc: 0.9955\n",
      "Epoch 8/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.1817 - acc: 0.9978\n",
      "Epoch 9/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.1377 - acc: 0.9978\n",
      "Epoch 10/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0512 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0285 - acc: 1.0000\n",
      "acc: 13.73%\n",
      "Epoch 1/20\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 2.6723 - acc: 0.0980\n",
      "Epoch 2/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 1.9269 - acc: 0.3942\n",
      "Epoch 3/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 1.4014 - acc: 0.5969\n",
      "Epoch 4/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.8407 - acc: 0.8775\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 5s 10ms/step - loss: 0.5114 - acc: 0.9644\n",
      "Epoch 6/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.3388 - acc: 0.9955\n",
      "Epoch 7/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.2205 - acc: 0.9978\n",
      "Epoch 8/20\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.1762 - acc: 0.9978\n",
      "Epoch 9/20\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.1025 - acc: 0.9978\n",
      "Epoch 11/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0846 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0795 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.0638 - acc: 0.9978\n",
      "Epoch 14/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.0536 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "449/449 [==============================] - 5s 10ms/step - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0324 - acc: 1.0000\n",
      "acc: 5.88%\n",
      "Epoch 1/20\n",
      "451/451 [==============================] - 7s 16ms/step - loss: 2.6183 - acc: 0.0909\n",
      "Epoch 2/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 1.9313 - acc: 0.4324\n",
      "Epoch 3/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 1.3357 - acc: 0.6829\n",
      "Epoch 4/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.8418 - acc: 0.8692\n",
      "Epoch 5/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.5281 - acc: 0.9645\n",
      "Epoch 6/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.3292 - acc: 0.9889\n",
      "Epoch 7/20\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.2281 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1524 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1258 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0261 - acc: 1.0000\n",
      "acc: 4.08%\n",
      "Epoch 1/20\n",
      "452/452 [==============================] - 6s 14ms/step - loss: 2.6840 - acc: 0.0885\n",
      "Epoch 2/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 2.0132 - acc: 0.4137\n",
      "Epoch 3/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 1.4664 - acc: 0.6327\n",
      "Epoch 4/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.9376 - acc: 0.8341\n",
      "Epoch 5/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.5589 - acc: 0.9690\n",
      "Epoch 6/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3628 - acc: 0.9912\n",
      "Epoch 7/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.2442 - acc: 0.9956\n",
      "Epoch 8/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1803 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1311 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1012 - acc: 0.9978\n",
      "Epoch 11/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0923 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0767 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0693 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0316 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0282 - acc: 1.0000\n",
      "acc: 12.50%\n",
      "Epoch 1/20\n",
      "452/452 [==============================] - 6s 14ms/step - loss: 2.6294 - acc: 0.1040\n",
      "Epoch 2/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 1.9420 - acc: 0.3850\n",
      "Epoch 3/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 1.4445 - acc: 0.6128\n",
      "Epoch 4/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.9175 - acc: 0.8673\n",
      "Epoch 5/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.5604 - acc: 0.9712\n",
      "Epoch 6/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3534 - acc: 0.9934\n",
      "Epoch 7/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.2288 - acc: 0.9978\n",
      "Epoch 8/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1727 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1367 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1115 - acc: 0.9978\n",
      "Epoch 11/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "452/452 [==============================] - 5s 11ms/step - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "452/452 [==============================] - 5s 12ms/step - loss: 0.0639 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "452/452 [==============================] - 5s 11ms/step - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "452/452 [==============================] - 5s 10ms/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "452/452 [==============================] - 5s 10ms/step - loss: 0.0276 - acc: 1.0000\n",
      "acc: 4.17%\n",
      "Epoch 1/20\n",
      "452/452 [==============================] - 6s 14ms/step - loss: 2.6758 - acc: 0.0796\n",
      "Epoch 2/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 1.8862 - acc: 0.4314\n",
      "Epoch 3/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 1.3175 - acc: 0.7124\n",
      "Epoch 4/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.8290 - acc: 0.8717\n",
      "Epoch 5/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.5010 - acc: 0.9602\n",
      "Epoch 6/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3111 - acc: 0.9934\n",
      "Epoch 7/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.2292 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1556 - acc: 1.0000\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452/452 [==============================] - 4s 10ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0962 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0944 - acc: 0.9978\n",
      "Epoch 12/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0574 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.0258 - acc: 1.0000\n",
      "acc: 4.17%\n",
      "Epoch 1/20\n",
      "454/454 [==============================] - 7s 15ms/step - loss: 2.8266 - acc: 0.0947\n",
      "Epoch 2/20\n",
      "454/454 [==============================] - 5s 11ms/step - loss: 1.9377 - acc: 0.3678\n",
      "Epoch 3/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 1.4122 - acc: 0.5947\n",
      "Epoch 4/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 0.8508 - acc: 0.8524\n",
      "Epoch 5/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 0.5204 - acc: 0.9692\n",
      "Epoch 6/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 0.3330 - acc: 0.9934\n",
      "Epoch 7/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 0.2226 - acc: 0.9956\n",
      "Epoch 8/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.1658 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.1391 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.1045 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "454/454 [==============================] - 5s 10ms/step - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "454/454 [==============================] - 4s 10ms/step - loss: 0.0309 - acc: 1.0000\n",
      "acc: 8.70%\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(re_data, label):\n",
    "#     model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=10 , input_shape=(1000, 29)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(re_data[train], label[train], epochs=20, batch_size=20)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(re_data[test], label[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardScaler 해줘보자\n",
    "scalers = {}\n",
    "for i in range(train_data.shape[1]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    train_data[:, i, :] = scalers[i].fit_transform(train[:, i, :])\n",
    "    vali_data[:,i,:] = scalers[i].transform(vali[:,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 50)                16000     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 17,230\n",
      "Trainable params: 17,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 2.3339 - acc: 0.1244\n",
      "Epoch 2/10\n",
      "450/450 [==============================] - 10s 21ms/step - loss: 2.2495 - acc: 0.1667\n",
      "Epoch 3/10\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 2.1905 - acc: 0.2178\n",
      "Epoch 4/10\n",
      "450/450 [==============================] - 10s 21ms/step - loss: 2.1399 - acc: 0.2667\n",
      "Epoch 5/10\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 2.0920 - acc: 0.3022\n",
      "Epoch 6/10\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 2.0456 - acc: 0.3533\n",
      "Epoch 7/10\n",
      "450/450 [==============================] - 10s 21ms/step - loss: 1.9992 - acc: 0.3889\n",
      "Epoch 8/10\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 1.9521 - acc: 0.4400\n",
      "Epoch 9/10\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 1.9047 - acc: 0.4800\n",
      "Epoch 10/10\n",
      "450/450 [==============================] - 10s 21ms/step - loss: 1.8559 - acc: 0.5178\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(1000,29)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])       \n",
    "print(model.summary())\n",
    "model.fit(train, train_label, epochs=10, batch_size=50)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(test, test_label, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10579996, 0.08500587, 0.18130967, 0.07627627, 0.06356674,\n",
       "       0.07083413, 0.06950507, 0.05162309, 0.12308872, 0.17299055],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "450  1\n",
       "451  0\n",
       "452  3\n",
       "453  0\n",
       "454  1\n",
       "455  1\n",
       "456  8\n",
       "457  2\n",
       "458  0\n",
       "459  3\n",
       "460  9\n",
       "461  4\n",
       "462  0\n",
       "463  5\n",
       "464  0\n",
       "465  6\n",
       "466  1\n",
       "467  7\n",
       "468  7\n",
       "469  8\n",
       "470  1\n",
       "471  9\n",
       "472  2\n",
       "473  0\n",
       "474  5\n",
       "475  1\n",
       "476  2\n",
       "477  2\n",
       "478  7\n",
       "479  3\n",
       "480  5\n",
       "481  4\n",
       "482  9\n",
       "483  7\n",
       "484  1\n",
       "485  8\n",
       "486  3\n",
       "487  9\n",
       "488  6\n",
       "489  0\n",
       "490  3\n",
       "491  1\n",
       "492  1\n",
       "493  2\n",
       "494  6\n",
       "495  3\n",
       "496  5\n",
       "497  7\n",
       "498  6\n",
       "499  8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
