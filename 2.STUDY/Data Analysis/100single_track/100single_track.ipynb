{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "dataset=np.loadtxt(\"100singletrack_1.csv\", delimiter=\",\")\n",
    "x=dataset[:,0:3]\n",
    "y=dataset[:,3:5]\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale=scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[350.    5.5   4. ]\n",
      " [350.    5.5   6. ]\n",
      " [350.    5.5   8. ]\n",
      " [350.    4.5   6. ]\n",
      " [350.    5.5   9. ]\n",
      " [350.    3.5   4. ]\n",
      " [350.    6.5   9. ]\n",
      " [350.    4.5   7. ]\n",
      " [350.    3.5   5. ]\n",
      " [350.    6.5   6. ]\n",
      " [350.    3.5   7. ]\n",
      " [350.    3.5   8. ]\n",
      " [350.    8.5   9. ]\n",
      " [350.    3.5   9. ]\n",
      " [350.    7.5   9. ]\n",
      " [350.    7.5   7. ]\n",
      " [350.    7.5   8. ]\n",
      " [350.    7.5   6. ]\n",
      " [350.    8.5   5. ]\n",
      " [350.    8.5   7. ]\n",
      " [450.    3.5   4. ]\n",
      " [450.    3.5   7. ]\n",
      " [450.    4.5   9. ]\n",
      " [450.    5.5   9. ]\n",
      " [450.    3.5   8. ]\n",
      " [450.    5.5   4. ]\n",
      " [450.    4.5   4. ]\n",
      " [450.    4.5   5. ]\n",
      " [450.    4.5   7. ]\n",
      " [450.    6.5   5. ]\n",
      " [450.    6.5   4. ]\n",
      " [450.    5.5   7. ]\n",
      " [450.    6.5   9. ]\n",
      " [450.    6.5   7. ]\n",
      " [450.    6.5   8. ]\n",
      " [450.    7.5   8. ]\n",
      " [450.    7.5   7. ]\n",
      " [450.    8.5   9. ]\n",
      " [450.    8.5   4. ]\n",
      " [450.    8.5   6. ]\n",
      " [450.    7.5   5. ]\n",
      " [450.    8.5   5. ]\n",
      " [450.    8.5   7. ]\n",
      " [450.    8.5   8. ]\n",
      " [550.    3.5   4. ]\n",
      " [550.    4.5   8. ]\n",
      " [550.    4.5   9. ]\n",
      " [550.    4.5   6. ]\n",
      " [550.    5.5   7. ]\n",
      " [550.    4.5   7. ]\n",
      " [550.    4.5   5. ]\n",
      " [550.    5.5   9. ]\n",
      " [550.    6.5   4. ]\n",
      " [550.    6.5   5. ]\n",
      " [550.    7.5   8. ]\n",
      " [550.    7.5   6. ]\n",
      " [550.    7.5   7. ]\n",
      " [550.    8.5   6. ]\n",
      " [550.    8.5   9. ]\n",
      " [550.    8.5   8. ]\n",
      " [650.    3.5   5. ]\n",
      " [650.    3.5   7. ]\n",
      " [650.    3.5   9. ]\n",
      " [650.    4.5   5. ]\n",
      " [650.    5.5   6. ]\n",
      " [650.    5.5   8. ]\n",
      " [650.    5.5   7. ]\n",
      " [650.    5.5   9. ]\n",
      " [650.    6.5   7. ]\n",
      " [650.    6.5   8. ]\n",
      " [650.    8.5   4. ]\n",
      " [650.    7.5   8. ]\n",
      " [650.    7.5   6. ]\n",
      " [650.    8.5   9. ]\n",
      " [650.    8.5   6. ]\n",
      " [750.    3.5   7. ]\n",
      " [750.    4.5   5. ]\n",
      " [750.    5.5   4. ]\n",
      " [750.    5.5   6. ]\n",
      " [750.    6.5   5. ]\n",
      " [750.    5.5   7. ]\n",
      " [750.    6.5   9. ]\n",
      " [750.    7.5   5. ]\n",
      " [750.    7.5   8. ]\n",
      " [750.    8.5   6. ]\n",
      " [750.    6.5   7. ]\n",
      " [750.    8.5   9. ]\n",
      " [850.    4.5   5. ]\n",
      " [850.    3.5   7. ]\n",
      " [850.    5.5   4. ]\n",
      " [850.    5.5   5. ]\n",
      " [850.    7.5   4. ]\n",
      " [850.    6.5   5. ]\n",
      " [850.    6.5   4. ]\n",
      " [850.    7.5   6. ]\n",
      " [850.    6.5   7. ]\n",
      " [850.    7.5   8. ]\n",
      " [850.    7.5   9. ]\n",
      " [850.    8.5   8. ]\n",
      " [850.    8.5   9. ]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.915 0.088]\n",
      " [0.903 0.1  ]\n",
      " [0.975 0.11 ]\n",
      " [1.035 0.118]\n",
      " [1.045 0.128]\n",
      " [1.158 0.135]\n",
      " [1.01  0.14 ]\n",
      " [0.975 0.143]\n",
      " [1.155 0.155]\n",
      " [1.095 0.16 ]\n",
      " [1.215 0.18 ]\n",
      " [1.195 0.188]\n",
      " [1.075 0.19 ]\n",
      " [1.18  0.193]\n",
      " [0.995 0.195]\n",
      " [0.933 0.2  ]\n",
      " [0.945 0.2  ]\n",
      " [0.958 0.208]\n",
      " [0.99  0.215]\n",
      " [0.96  0.215]\n",
      " [1.13  0.098]\n",
      " [1.163 0.103]\n",
      " [1.04  0.11 ]\n",
      " [1.2   0.11 ]\n",
      " [1.188 0.12 ]\n",
      " [1.118 0.12 ]\n",
      " [1.168 0.123]\n",
      " [1.14  0.133]\n",
      " [1.18  0.135]\n",
      " [1.043 0.143]\n",
      " [1.218 0.148]\n",
      " [1.128 0.16 ]\n",
      " [1.148 0.168]\n",
      " [1.153 0.175]\n",
      " [1.078 0.178]\n",
      " [1.08  0.178]\n",
      " [1.225 0.18 ]\n",
      " [1.153 0.195]\n",
      " [1.253 0.223]\n",
      " [1.048 0.223]\n",
      " [1.198 0.243]\n",
      " [1.113 0.245]\n",
      " [1.083 0.245]\n",
      " [1.073 0.255]\n",
      " [1.388 0.12 ]\n",
      " [1.29  0.14 ]\n",
      " [1.293 0.145]\n",
      " [1.155 0.155]\n",
      " [1.198 0.158]\n",
      " [1.305 0.16 ]\n",
      " [1.383 0.165]\n",
      " [1.208 0.175]\n",
      " [1.373 0.175]\n",
      " [1.5   0.178]\n",
      " [1.098 0.213]\n",
      " [1.183 0.223]\n",
      " [1.21  0.233]\n",
      " [1.08  0.243]\n",
      " [1.19  0.243]\n",
      " [1.198 0.268]\n",
      " [1.345 0.088]\n",
      " [1.478 0.133]\n",
      " [1.463 0.145]\n",
      " [1.353 0.175]\n",
      " [1.448 0.198]\n",
      " [1.35  0.2  ]\n",
      " [1.455 0.205]\n",
      " [1.373 0.205]\n",
      " [1.32  0.22 ]\n",
      " [1.268 0.22 ]\n",
      " [1.425 0.23 ]\n",
      " [1.388 0.288]\n",
      " [1.405 0.298]\n",
      " [1.513 0.298]\n",
      " [1.263 0.32 ]\n",
      " [1.515 0.188]\n",
      " [1.453 0.188]\n",
      " [1.605 0.193]\n",
      " [1.468 0.243]\n",
      " [1.313 0.27 ]\n",
      " [1.38  0.275]\n",
      " [1.235 0.278]\n",
      " [1.533 0.295]\n",
      " [1.363 0.305]\n",
      " [1.32  0.315]\n",
      " [1.303 0.325]\n",
      " [1.29  0.37 ]\n",
      " [1.66  0.123]\n",
      " [1.415 0.148]\n",
      " [1.535 0.16 ]\n",
      " [1.588 0.16 ]\n",
      " [1.633 0.193]\n",
      " [1.675 0.208]\n",
      " [1.803 0.228]\n",
      " [1.368 0.233]\n",
      " [1.505 0.243]\n",
      " [1.4   0.248]\n",
      " [1.298 0.31 ]\n",
      " [1.513 0.35 ]\n",
      " [1.52  0.408]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.4 0. ]\n",
      " [0.  0.4 0.4]\n",
      " [0.  0.4 0.8]\n",
      " [0.  0.2 0.4]\n",
      " [0.  0.4 1. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.6 1. ]\n",
      " [0.  0.2 0.6]\n",
      " [0.  0.  0.2]\n",
      " [0.  0.6 0.4]\n",
      " [0.  0.  0.6]\n",
      " [0.  0.  0.8]\n",
      " [0.  1.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.8 1. ]\n",
      " [0.  0.8 0.6]\n",
      " [0.  0.8 0.8]\n",
      " [0.  0.8 0.4]\n",
      " [0.  1.  0.2]\n",
      " [0.  1.  0.6]\n",
      " [0.2 0.  0. ]\n",
      " [0.2 0.  0.6]\n",
      " [0.2 0.2 1. ]\n",
      " [0.2 0.4 1. ]\n",
      " [0.2 0.  0.8]\n",
      " [0.2 0.4 0. ]\n",
      " [0.2 0.2 0. ]\n",
      " [0.2 0.2 0.2]\n",
      " [0.2 0.2 0.6]\n",
      " [0.2 0.6 0.2]\n",
      " [0.2 0.6 0. ]\n",
      " [0.2 0.4 0.6]\n",
      " [0.2 0.6 1. ]\n",
      " [0.2 0.6 0.6]\n",
      " [0.2 0.6 0.8]\n",
      " [0.2 0.8 0.8]\n",
      " [0.2 0.8 0.6]\n",
      " [0.2 1.  1. ]\n",
      " [0.2 1.  0. ]\n",
      " [0.2 1.  0.4]\n",
      " [0.2 0.8 0.2]\n",
      " [0.2 1.  0.2]\n",
      " [0.2 1.  0.6]\n",
      " [0.2 1.  0.8]\n",
      " [0.4 0.  0. ]\n",
      " [0.4 0.2 0.8]\n",
      " [0.4 0.2 1. ]\n",
      " [0.4 0.2 0.4]\n",
      " [0.4 0.4 0.6]\n",
      " [0.4 0.2 0.6]\n",
      " [0.4 0.2 0.2]\n",
      " [0.4 0.4 1. ]\n",
      " [0.4 0.6 0. ]\n",
      " [0.4 0.6 0.2]\n",
      " [0.4 0.8 0.8]\n",
      " [0.4 0.8 0.4]\n",
      " [0.4 0.8 0.6]\n",
      " [0.4 1.  0.4]\n",
      " [0.4 1.  1. ]\n",
      " [0.4 1.  0.8]\n",
      " [0.6 0.  0.2]\n",
      " [0.6 0.  0.6]\n",
      " [0.6 0.  1. ]\n",
      " [0.6 0.2 0.2]\n",
      " [0.6 0.4 0.4]\n",
      " [0.6 0.4 0.8]\n",
      " [0.6 0.4 0.6]\n",
      " [0.6 0.4 1. ]\n",
      " [0.6 0.6 0.6]\n",
      " [0.6 0.6 0.8]\n",
      " [0.6 1.  0. ]\n",
      " [0.6 0.8 0.8]\n",
      " [0.6 0.8 0.4]\n",
      " [0.6 1.  1. ]\n",
      " [0.6 1.  0.4]\n",
      " [0.8 0.  0.6]\n",
      " [0.8 0.2 0.2]\n",
      " [0.8 0.4 0. ]\n",
      " [0.8 0.4 0.4]\n",
      " [0.8 0.6 0.2]\n",
      " [0.8 0.4 0.6]\n",
      " [0.8 0.6 1. ]\n",
      " [0.8 0.8 0.2]\n",
      " [0.8 0.8 0.8]\n",
      " [0.8 1.  0.4]\n",
      " [0.8 0.6 0.6]\n",
      " [0.8 1.  1. ]\n",
      " [1.  0.2 0.2]\n",
      " [1.  0.  0.6]\n",
      " [1.  0.4 0. ]\n",
      " [1.  0.4 0.2]\n",
      " [1.  0.8 0. ]\n",
      " [1.  0.6 0.2]\n",
      " [1.  0.6 0. ]\n",
      " [1.  0.8 0.4]\n",
      " [1.  0.6 0.6]\n",
      " [1.  0.8 0.8]\n",
      " [1.  0.8 1. ]\n",
      " [1.  1.  0.8]\n",
      " [1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "print(xscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01333333 0.        ]\n",
      " [0.         0.0375    ]\n",
      " [0.08       0.06875   ]\n",
      " [0.14666667 0.09375   ]\n",
      " [0.15777778 0.125     ]\n",
      " [0.28333333 0.146875  ]\n",
      " [0.11888889 0.1625    ]\n",
      " [0.08       0.171875  ]\n",
      " [0.28       0.209375  ]\n",
      " [0.21333333 0.225     ]\n",
      " [0.34666667 0.2875    ]\n",
      " [0.32444444 0.3125    ]\n",
      " [0.19111111 0.31875   ]\n",
      " [0.30777778 0.328125  ]\n",
      " [0.10222222 0.334375  ]\n",
      " [0.03333333 0.35      ]\n",
      " [0.04666667 0.35      ]\n",
      " [0.06111111 0.375     ]\n",
      " [0.09666667 0.396875  ]\n",
      " [0.06333333 0.396875  ]\n",
      " [0.25222222 0.03125   ]\n",
      " [0.28888889 0.046875  ]\n",
      " [0.15222222 0.06875   ]\n",
      " [0.33       0.06875   ]\n",
      " [0.31666667 0.1       ]\n",
      " [0.23888889 0.1       ]\n",
      " [0.29444444 0.109375  ]\n",
      " [0.26333333 0.140625  ]\n",
      " [0.30777778 0.146875  ]\n",
      " [0.15555556 0.171875  ]\n",
      " [0.35       0.1875    ]\n",
      " [0.25       0.225     ]\n",
      " [0.27222222 0.25      ]\n",
      " [0.27777778 0.271875  ]\n",
      " [0.19444444 0.28125   ]\n",
      " [0.19666667 0.28125   ]\n",
      " [0.35777778 0.2875    ]\n",
      " [0.27777778 0.334375  ]\n",
      " [0.38888889 0.421875  ]\n",
      " [0.16111111 0.421875  ]\n",
      " [0.32777778 0.484375  ]\n",
      " [0.23333333 0.490625  ]\n",
      " [0.2        0.490625  ]\n",
      " [0.18888889 0.521875  ]\n",
      " [0.53888889 0.1       ]\n",
      " [0.43       0.1625    ]\n",
      " [0.43333333 0.178125  ]\n",
      " [0.28       0.209375  ]\n",
      " [0.32777778 0.21875   ]\n",
      " [0.44666667 0.225     ]\n",
      " [0.53333333 0.240625  ]\n",
      " [0.33888889 0.271875  ]\n",
      " [0.52222222 0.271875  ]\n",
      " [0.66333333 0.28125   ]\n",
      " [0.21666667 0.390625  ]\n",
      " [0.31111111 0.421875  ]\n",
      " [0.34111111 0.453125  ]\n",
      " [0.19666667 0.484375  ]\n",
      " [0.31888889 0.484375  ]\n",
      " [0.32777778 0.5625    ]\n",
      " [0.49111111 0.        ]\n",
      " [0.63888889 0.140625  ]\n",
      " [0.62222222 0.178125  ]\n",
      " [0.5        0.271875  ]\n",
      " [0.60555556 0.34375   ]\n",
      " [0.49666667 0.35      ]\n",
      " [0.61333333 0.365625  ]\n",
      " [0.52222222 0.365625  ]\n",
      " [0.46333333 0.4125    ]\n",
      " [0.40555556 0.4125    ]\n",
      " [0.58       0.44375   ]\n",
      " [0.53888889 0.625     ]\n",
      " [0.55777778 0.65625   ]\n",
      " [0.67777778 0.65625   ]\n",
      " [0.4        0.725     ]\n",
      " [0.68       0.3125    ]\n",
      " [0.61111111 0.3125    ]\n",
      " [0.78       0.328125  ]\n",
      " [0.62777778 0.484375  ]\n",
      " [0.45555556 0.56875   ]\n",
      " [0.53       0.584375  ]\n",
      " [0.36888889 0.59375   ]\n",
      " [0.7        0.646875  ]\n",
      " [0.51111111 0.678125  ]\n",
      " [0.46333333 0.709375  ]\n",
      " [0.44444444 0.740625  ]\n",
      " [0.43       0.88125   ]\n",
      " [0.84111111 0.109375  ]\n",
      " [0.56888889 0.1875    ]\n",
      " [0.70222222 0.225     ]\n",
      " [0.76111111 0.225     ]\n",
      " [0.81111111 0.328125  ]\n",
      " [0.85777778 0.375     ]\n",
      " [1.         0.4375    ]\n",
      " [0.51666667 0.453125  ]\n",
      " [0.66888889 0.484375  ]\n",
      " [0.55222222 0.5       ]\n",
      " [0.43888889 0.69375   ]\n",
      " [0.67777778 0.81875   ]\n",
      " [0.68555556 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (75, 2) was passed for an output of shape (None, 1) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-ee349d0b2b18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         steps=steps_per_epoch)\n\u001b[0m\u001b[0;32m    553\u001b[0m     (x, y, sample_weights,\n\u001b[0;32m    554\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2487\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2489\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    808\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    809\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (75, 2) was passed for an output of shape (None, 1) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    ">>> history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
